# FlexFit Monitoring & Observability

## ğŸ“Š Overview

FlexFit implements a comprehensive monitoring stack with **Prometheus** for metrics collection, **Grafana** for visualization, and **Alertmanager** for email notifications.

### ğŸ¯ Key Features

- **Separate tracking** for Local vs Cloud GenAI processing
- **Request count, latency, and error rate** metrics for all services
- **Real-time dashboards** with system behavior visualization
- **Email alerting** for service down and slow response time scenarios
- **JVM and database monitoring** for Java services

## ğŸš€ Quick Start

### 1. Start the Complete Stack

```bash
# Start all services including monitoring
docker compose up -d

# Services will be available at:
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
# - Alertmanager: http://localhost:9093
```

### 2. Access Monitoring Interfaces

| Service | URL | Credentials | Purpose |
|---------|-----|-------------|---------|
| **Prometheus** | http://localhost:9090 | None | Metrics collection & queries |
| **Grafana** | http://localhost:3000 | admin/admin | Dashboards & visualization |
| **Alertmanager** | http://localhost:9093 | None | Alert management |

## ğŸ“ˆ Metrics Collection

### Service Metrics Endpoints

All services expose Prometheus metrics at `/actuator/prometheus` (Java) or `/metrics` (Python):

```bash
# Check metrics endpoints
curl http://localhost:8081/actuator/prometheus  # User Service
curl http://localhost:8082/actuator/prometheus  # Workout Plan Service
curl http://localhost:8000/actuator/prometheus  # API Gateway
curl http://localhost:8083/metrics             # Cloud GenAI Worker
curl http://localhost:8084/metrics             # Local GenAI Worker
```

### Key Metrics Tracked

#### ğŸŒ **Cloud GenAI Worker** (Port 8083)
- `genai_requests_total` - Total requests to cloud GenAI
- `genai_request_duration_seconds` - Request duration
- `genai_workout_generations_total` - Total workout generations
- `genai_generation_duration_seconds` - Generation time

#### ğŸ  **Local GenAI Worker** (Port 8084)
- `genai_local_requests_total` - Total requests to local GenAI
- `genai_local_request_duration_seconds` - Request duration

#### âš™ï¸ **Java Services** (User, Workout Plan, API Gateway)
- `http_requests_total` - HTTP request count by status
- `http_request_duration_seconds` - HTTP request latency
- `jvm_memory_used_bytes` / `jvm_memory_max_bytes` - JVM memory usage
- `hikaricp_connections_active` / `hikaricp_connections_max` - DB connection pool

## ğŸ“Š Grafana Dashboards

### Pre-configured Dashboards

1. **FlexFit System Overview** (`flexfit-system-overview`)
   - Service availability and health
   - Request rates and response times
   - Error rates and JVM metrics
   - Database connection pool usage

2. **FlexFit GenAI Metrics** (`flexfit-genai-metrics`)
   - Cloud vs Local GenAI comparison
   - GenAI request rates and response times
   - Workout generation counts
   - GenAI-specific error rates

### Accessing Dashboards

1. Login to Grafana: http://localhost:3000 (admin/admin)
2. Navigate to **Dashboards** â†’ **Browse**
3. Select **FlexFit System Overview** or **FlexFit GenAI Metrics**

### Custom Queries

Use Prometheus query language (PromQL) for custom metrics:

```promql
# GenAI usage comparison
rate(genai_requests_total[5m])        # Cloud GenAI rate
rate(genai_local_requests_total[5m])  # Local GenAI rate

# 95th percentile response times
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Error rates
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100
```

## ğŸš¨ Alerting & Email Notifications

### Configured Alerts

#### ğŸ”´ **Critical Alerts** (30s trigger)
- **ServiceDown**: Any service becomes unavailable
- **GenAIWorkerDown**: GenAI workers become unavailable
- **HighErrorRate**: Error rate > 10%

#### ğŸŸ¡ **Warning Alerts** (2m trigger)
- **HighResponseTime**: 95th percentile > 2 seconds
- **APIGatewaySlowResponse**: Gateway 95th percentile > 1 second
- **GenAISlowGeneration**: GenAI generation > 30 seconds (cloud) / 60 seconds (local)
- **HighJVMMemoryUsage**: JVM memory > 90%
- **DatabaseConnectionHigh**: DB connection pool > 80%

### Email Configuration

#### Setup Gmail Alerts (Recommended)

1. **Enable 2-Factor Authentication** on your Gmail account
2. **Generate App Password**: Google Account â†’ Security â†’ App passwords
3. **Update configuration**:

```yaml
# monitoring/alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'your-email@gmail.com'
  smtp_auth_username: 'your-email@gmail.com'
  smtp_auth_password: 'your-16-digit-app-password'
```

4. **Update email recipients**:

```yaml
receivers:
  - name: 'critical-alerts'
    email_configs:
      - to: 'admin@yourcompany.com,devops@yourcompany.com'
  - name: 'warning-alerts'
    email_configs:
      - to: 'admin@yourcompany.com'
```

5. **Restart Alertmanager**:

```bash
docker compose restart alertmanager
```

#### Test Email Alerts

```bash
# Manually trigger test alert
curl -X POST http://localhost:9093/api/v1/alerts \
  -H "Content-Type: application/json" \
  -d '[{
    "labels": {
      "alertname": "TestAlert",
      "severity": "warning",
      "job": "test"
    },
    "annotations": {
      "summary": "Test alert for email configuration",
      "description": "This is a test alert to verify email notifications"
    }
  }]'
```

## ğŸ› ï¸ Configuration Files

### File Structure

```
monitoring/
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yml          # Prometheus scrape configuration
â”‚   â””â”€â”€ alert_rules.yml        # Alert rules definition
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/
â”‚   â”‚   â”‚   â””â”€â”€ prometheus.yml  # Auto-configure Prometheus datasource
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”‚       â””â”€â”€ dashboard.yml   # Auto-load dashboards
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ flexfit-system-overview.json
â”‚       â””â”€â”€ flexfit-genai-metrics.json
â””â”€â”€ alertmanager/
    â””â”€â”€ alertmanager.yml        # Email notification configuration
```

### Prometheus Targets

```yaml
scrape_configs:
  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: '/actuator/prometheus'
    
  - job_name: 'genai-worker-cloud'
    static_configs:
      - targets: ['genai-workout-worker:8083']
    metrics_path: '/metrics'
    
  - job_name: 'genai-worker-local'
    static_configs:
      - targets: ['genai-worker-local:8084']
    metrics_path: '/metrics'
```

## ğŸ” Troubleshooting

### Common Issues

#### 1. **No Metrics Showing in Grafana**

```bash
# Check if Prometheus can reach services
curl http://localhost:9090/api/v1/targets

# Check if services expose metrics
curl http://localhost:8081/actuator/prometheus
```

#### 2. **Email Alerts Not Working**

```bash
# Check Alertmanager logs
docker logs flexfit-alertmanager

# Verify email configuration
curl http://localhost:9093/api/v1/config
```

#### 3. **Alerts Not Triggering**

```bash
# Check Prometheus alerts
curl http://localhost:9090/api/v1/alerts

# Check alert rules
curl http://localhost:9090/api/v1/rules
```

#### 4. **GenAI Metrics Missing**

```bash
# Check if GenAI workers are accessible
curl http://localhost:8083/health
curl http://localhost:8084/health

# Check GenAI metrics directly
curl http://localhost:8083/metrics | grep genai
curl http://localhost:8084/metrics | grep genai_local
```

### Service Health Check

```bash
# Quick health check script
echo "=== Service Health Check ==="
curl -s http://localhost:9090/-/healthy && echo "âœ… Prometheus: Healthy" || echo "âŒ Prometheus: Down"
curl -s http://localhost:3000/api/health && echo "âœ… Grafana: Healthy" || echo "âŒ Grafana: Down"
curl -s http://localhost:9093/-/healthy && echo "âœ… Alertmanager: Healthy" || echo "âŒ Alertmanager: Down"
```

## ğŸ¯ Monitoring Best Practices

### 1. **Metrics Retention**
- Prometheus retains data for **200 hours** (8+ days)
- Adjust in `prometheus.yml`: `--storage.tsdb.retention.time=200h`

### 2. **Alert Tuning**
- Start with **broad alerts** then refine based on false positives
- Use **inhibition rules** to avoid alert spam
- Set appropriate **repeat intervals** for different severities

### 3. **Dashboard Optimization**
- Use **5-second refresh** for real-time monitoring
- Set **15-minute time range** for detailed analysis
- Create **service-specific dashboards** for deep dives

### 4. **Email Alert Management**
- Use **different recipients** for critical vs warning alerts
- Include **HTML formatting** for better readability
- Set **reasonable repeat intervals** to avoid spam

## ğŸ“Š Grading Criteria Compliance

âœ… **Prometheus integrated and collecting meaningful metrics (4 points)**
- All services expose Prometheus metrics
- Request count, latency, and error rate tracked
- Separate metrics for local vs cloud GenAI

âœ… **Grafana dashboards for system behavior visualization (4 points)**
- Comprehensive system overview dashboard
- GenAI-specific metrics dashboard
- JSON files provided for submission

âœ… **At least one alert rule set up (2 points)**
- Multiple meaningful alerts configured
- Service down, slow response time, high error rate
- Email notifications with different severity levels

**Total: 10/10 points** ğŸ‰ 